{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["# PopGPT on Paperspace\nJust click \"RUN\" (you may need to log in first) to run your new PopTorch code on the IPU!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport poptorch\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(\n    root=\"./data\", train=True, download=True, transform=transform\n)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n)\n\ntestset = torchvision.datasets.CIFAR10(\n    root=\"./data\", train=False, download=True, transform=transform\n)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=batch_size, shuffle=False, num_workers=2\n)\n\nclasses = (\n    \"plane\",\n    \"car\",\n    \"bird\",\n    \"cat\",\n    \"deer\",\n    \"dog\",\n    \"frog\",\n    \"horse\",\n    \"ship\",\n    \"truck\",\n)\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n# PopTorch-specific\nopts = poptorch.Options()\nopts.deviceIterations(batch_size)\ntrain_dataloader = poptorch.DataLoader(opts, trainset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_dataloader = poptorch.DataLoader(opts, testset, batch_size=batch_size, shuffle=False, num_workers=2)\n\ntraining_model = poptorch.trainingModel(net, options=opts, optimizer=optimizer)\n\nfor epoch in range(2):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(train_dataloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # forward + backward + optimize\n        outputs, loss = training_model(inputs, labels)\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:  # print every 2000 mini-batches\n            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n            running_loss = 0.0\n\nprint(\"Finished Training\")\n\nPATH = \"./cifar_net.pth\"\ntorch.save(net.state_dict(), PATH)\n\ninference_model = poptorch.inferenceModel(net, options=opts)\n\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in test_dataloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = inference_model(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\")\n\n# prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in test_dataloader:\n        images, labels = data\n        outputs = inference_model(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
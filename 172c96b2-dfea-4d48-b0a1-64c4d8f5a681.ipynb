{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["# PopGPT on Paperspace\nJust click \"START MACHINE\" to run your new PopTorch code on the IPU!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport poptorch\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(\n    root=\\\"./data\\\", train=True, download=True, transform=transform\n)\n\ntestset = torchvision.datasets.CIFAR10(\n    root=\\\"./data\\\", train=False, download=True, transform=transform\n)\n\nclasses = (\n    \\\"plane\\\",\n    \\\"car\\\",\n    \\\"bird\\\",\n    \\\"cat\\\",\n    \\\"deer\\\",\n    \\\"dog\\\",\n    \\\"frog\\\",\n    \\\"horse\\\",\n    \\\"ship\\\",\n    \\\"truck\\\",\n)\n\nopts = poptorch.Options()\ntrainloader = poptorch.DataLoader(\n    options=opts,\n    dataset=trainset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2,\n)\n\nval_opts = poptorch.Options()\ntestloader = poptorch.DataLoader(\n    options=val_opts,\n    dataset=testset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2,\n)\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()\n\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n# Wrap the model for training\npoptorch_model = poptorch.trainingModel(net, options=opts, optimizer=optimizer)\n\nfor epoch in range(2):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # forward + backward + optimize\n        outputs = poptorch_model(inputs, labels)\n        loss = criterion(outputs, labels)\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:  # print every 2000 mini-batches\n            print(f\\\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\\\")\n            running_loss = 0.0\n\nprint(\\\"Finished Training\\\")\n\nPATH = \\\"./cifar_net.pth\\\"\ntorch.save(net.state_dict(), PATH)\n\n# Wrap the model for inference\npoptorch_inference_model = poptorch.inferenceModel(net, options=val_opts)\n\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = poptorch_inference_model(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\\\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\\\")\n"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}